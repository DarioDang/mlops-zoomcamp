{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262d5037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9eaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "import pandas as pd \n",
    "import pickle\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69bc1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 22:38:00 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/05/04 22:38:00 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/05/04 22:38:01 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/mlops-zoomcamp/02-experiment-tracking/mlruns/1', creation_time=1746398281006, experiment_id='1', last_update_time=1746398281006, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow \n",
    "mlflow.set_tracking_uri(\"sqlite:///mflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a995e3",
   "metadata": {},
   "source": [
    "### Put all the proccessing into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006c6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    \"Write a function to read and preprocessing data\"\n",
    "    # Read the dataset\n",
    "    df_taxi = pd.read_parquet(filename)\n",
    "\n",
    "    # Adjust dropoff & pickup to pandas datetime \n",
    "    df_taxi['lpep_pickup_datetime'] = pd.to_datetime(df_taxi.lpep_pickup_datetime)\n",
    "    df_taxi['lpep_dropoff_datetime'] = pd.to_datetime(df_taxi.lpep_dropoff_datetime)\n",
    "    \n",
    "    # Calculate the duration (drop_off -  pick_up)\n",
    "    df_taxi['duration'] = df_taxi.lpep_dropoff_datetime - df_taxi.lpep_pickup_datetime\n",
    "    \n",
    "    # Adjust the duration in minutes for prediction \n",
    "    df_taxi['duration_minutes'] = df_taxi['duration'].dt.total_seconds() / 60\n",
    "\n",
    "    # Since there are a lot of duration less than 1 minutes. We filter only duration between 1 minutes to 99% percentile\n",
    "    df_taxi = df_taxi[(df_taxi['duration_minutes'] >= 1) & (df_taxi['duration_minutes'] <= 60)]\n",
    "\n",
    "    # Feature Engineering \n",
    "    categorical_variables = ['PULocationID', 'DOLocationID']\n",
    "    numerical_variables = ['trip_distance']\n",
    "\n",
    "    # Convert it into \"str\"\n",
    "    df_taxi[categorical_variables] = df_taxi[categorical_variables].astype(str)\n",
    "    \n",
    "    return df_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e108a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('../00-Dataset/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('../00-Dataset/green_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db72730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73908, 61921)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eee79d",
   "metadata": {},
   "source": [
    "### Create the training pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae7b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "categorical_variables = ['PULocationID', 'DOLocationID']\n",
    "numerical_variables = ['trip_distance']\n",
    "\n",
    "# Vectorizer the training variables \n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Convert it into dictionary \n",
    "train_dicts = df_train[categorical_variables + numerical_variables].to_dict(orient = 'records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Create the validation set \n",
    "val_dicts = df_val[categorical_variables + numerical_variables].to_dict(orient = 'records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44f5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Prediction_Variables \n",
    "predictor = 'duration_minutes'\n",
    "y_train = df_train[predictor].values\n",
    "y_val = df_val[predictor].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ac1519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.47390313604031"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model \n",
    "lr = LinearRegression() \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make a prediction \n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "# Calculate the performance (RMSE)\n",
    "mean_squared_error(y_val, y_pred, squared = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61b476",
   "metadata": {},
   "source": [
    "### Try with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eeb0be27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.47054920225702"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model \n",
    "lr = Lasso(alpha= 0.0001) \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make a prediction \n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "# Calculate the performance (RMSE)\n",
    "mean_squared_error(y_val, y_pred, squared = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb2f20",
   "metadata": {},
   "source": [
    "### Try To Combine the input features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde48eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d52ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "categorical_variables = ['PU_DO']  #['PULocationID', 'DOLocationID']\n",
    "numerical_variables = ['trip_distance']\n",
    "\n",
    "# Vectorizer the training variables \n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Convert it into dictionary \n",
    "train_dicts = df_train[categorical_variables + numerical_variables].to_dict(orient = 'records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Create the validation set \n",
    "val_dicts = df_val[categorical_variables + numerical_variables].to_dict(orient = 'records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6990868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Prediction_Variables \n",
    "predictor = 'duration_minutes'\n",
    "y_train = df_train[predictor].values\n",
    "y_val = df_val[predictor].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084c1174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.479586896299878"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model \n",
    "lr = LinearRegression() \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make a prediction \n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "# Calculate the performance (RMSE)\n",
    "mean_squared_error(y_val, y_pred, squared = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a6d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
